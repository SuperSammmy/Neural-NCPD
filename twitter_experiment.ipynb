{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(1,\"./src\")\n",
    "\n",
    "from NNCPD import NNCPD, weights_H, Energy_Loss_Tensor2, Energy_Loss_Tensor, Recon_Loss, Recon_Loss_Straight, Recon_Loss_NMF, L21_Norm, outer_product, outer_product_np, PTF, random_NNCPD, Fro_Norm\n",
    "from lsqnonneg_module import LsqNonneg\n",
    "from trainNNCPD import train\n",
    "#\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from writer import Writer\n",
    "\n",
    "\n",
    "import tensorly as tl\n",
    "from tensorly import unfold as tl_unfold\n",
    "from tensorly.decomposition import parafac, non_negative_parafac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.load(\"./data/words_100.npy\", allow_pickle=True)\n",
    "X = np.load(\"./data/tweets_bag_100.npy\", allow_pickle=True)\n",
    "\n",
    "\n",
    "X = X.reshape((8, 10, -1))\n",
    "\n",
    "X = torch.from_numpy(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Neural NCPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r=8\n",
    "n1,n2,n3 = X.shape\n",
    "net = NNCPD([n1,4,2],[n2,4,2],[n3,4,2])\n",
    "\n",
    "loss_func = Energy_Loss_Tensor()\n",
    "\n",
    "history_unsupervised = train(net, X, loss_func, r, epoch = 15000, lr1 = 0, lr2 = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = history_unsupervised.get('A_X1')[-1].detach().numpy()\n",
    "X_2 = history_unsupervised.get('B_X1')[-1].detach().numpy()\n",
    "X_3 = history_unsupervised.get('C_X1')[-1].detach().numpy()\n",
    "\n",
    "A_A1 = history_unsupervised.get('A_A1')[-1].detach().numpy()\n",
    "A_S1 = history_unsupervised.get('A_S1')[-1].detach().numpy()\n",
    "B_A1 = history_unsupervised.get('B_A1')[-1].detach().numpy()\n",
    "B_S1 = history_unsupervised.get('B_S1')[-1].detach().numpy()\n",
    "C_A1 = history_unsupervised.get('C_A1')[-1].detach().numpy()\n",
    "C_S1 = history_unsupervised.get('C_S1')[-1].detach().numpy()\n",
    "\n",
    "A_A2 = history_unsupervised.get('A_A2')[-1].detach().numpy()\n",
    "A_S2 = history_unsupervised.get('A_S2')[-1].detach().numpy()\n",
    "B_A2 = history_unsupervised.get('B_A2')[-1].detach().numpy()\n",
    "B_S2 = history_unsupervised.get('B_S2')[-1].detach().numpy()\n",
    "C_A2 = history_unsupervised.get('C_A2')[-1].detach().numpy()\n",
    "C_S2 = history_unsupervised.get('C_S2')[-1].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = np.empty((7,8), dtype=object)\n",
    "\n",
    "for i in range(keywords.shape[1]):\n",
    "    keywords[0,i] = \"Topic \" + str(i+1)\n",
    "    keywords[1,i] = \"-------\"\n",
    "    \n",
    "C = X_3\n",
    "\n",
    "for i in range(C.shape[1]):\n",
    "    col = C[:,i]\n",
    "    top = col.argsort()\n",
    "    top = top[-5:][::-1]\n",
    "\n",
    "    keywords[2:,i] = words[top] \n",
    "\n",
    "print(\"RANK 8 KEYWORDS:\")  \n",
    "print(\"------------------\")\n",
    "col_widths = [max([len(keywords[i][j]) for i in range(keywords.shape[0])])+2 for j in range(keywords.shape[1])]\n",
    "for row in keywords:\n",
    "    print(\"\".join(row[i].ljust(col_widths[i]) for i in range(len(row))))\n",
    "    \n",
    "\n",
    "C = C_A1\n",
    "\n",
    "keywords = np.empty((7,4), dtype=object)\n",
    "\n",
    "for i in range(keywords.shape[1]):\n",
    "    keywords[0,i] = \"Topic \" + str(i+1)\n",
    "    keywords[1,i] = \"-------\"\n",
    "\n",
    "for i in range(C.shape[1]):\n",
    "    col = C[:,i]\n",
    "    top = col.argsort()\n",
    "    top = top[-5:][::-1]\n",
    "\n",
    "    keywords[2:,i] = words[top]\n",
    "\n",
    "print(\"\")\n",
    "print(\"RANK 4 KEYWORDS:\")  \n",
    "print(\"------------------\")\n",
    "\n",
    "col_widths = [max([len(keywords[i][j]) for i in range(keywords.shape[0])])+2 for j in range(keywords.shape[1])]\n",
    "for row in keywords:\n",
    "    print(\"\".join(row[i].ljust(col_widths[i]) for i in range(len(row))))\n",
    "\n",
    "\n",
    "C = np.dot(C_A1, C_A2)\n",
    "\n",
    "keywords = np.empty((7,2), dtype=object)\n",
    "\n",
    "for i in range(keywords.shape[1]):\n",
    "    keywords[0,i] = \"Topic \" + str(i+1)\n",
    "    keywords[1,i] = \"-------\"\n",
    "\n",
    "for i in range(C.shape[1]):\n",
    "    col = C[:,i]\n",
    "    top = col.argsort()\n",
    "    top = top[-5:][::-1]\n",
    "\n",
    "    keywords[2:,i] = words[top]\n",
    "\n",
    "print(\"\")\n",
    "print(\"RANK 2 KEYWORDS:\")  \n",
    "print(\"------------------\")\n",
    "\n",
    "col_widths = [max([len(keywords[i][j]) for i in range(keywords.shape[0])])+2 for j in range(keywords.shape[1])]\n",
    "for row in keywords:\n",
    "    print(\"\".join(row[i].ljust(col_widths[i]) for i in range(len(row))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, constrained_layout=True, figsize=(12,5))\n",
    "color = \"viridis\"\n",
    "\n",
    "plt.sca(axs[0])\n",
    "plt.yticks(range(8), ['Clinton', 'Kaine', 'O\\'Malley', 'Sanders', 'Cruz', 'Kasich', 'Rubio', 'Trump'], fontsize=22)\n",
    "plt.xticks(range(8), range(1,9), fontsize=22)\n",
    "plt.sca(axs[1])\n",
    "plt.xticks(range(8), range(1,9), fontsize=22)\n",
    "plt.yticks(range(10), ['Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov'], fontsize=22)\n",
    "\n",
    "axs[0].imshow(X_1, cmap=plt.get_cmap(color))\n",
    "axs[1].imshow(X_2, cmap=plt.get_cmap(color))\n",
    "#axs[2].imshow(C_approx, cmap=plt.get_cmap(color))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_W(A, B, C, H_A, H_B, H_C):\n",
    "    \n",
    "    alphas = []\n",
    "    n_1, r = A.shape\n",
    "    n_2, r = B.shape\n",
    "    n_3, r = C.shape\n",
    "    weights = np.zeros((r, r, 2))\n",
    "    \n",
    "    \n",
    "    for col in range(r):\n",
    "        for it in range(r**2):\n",
    "            i = int(it % r)\n",
    "            j = int((it/r) % r)\n",
    "\n",
    "            weights[col, i, 0] += np.sum(H_A[i] * H_B[j] * H_C[col]);\n",
    "            weights[col, j, 1] += np.sum(H_A[i] * H_B[j] * H_C[col]);\n",
    "         \n",
    "\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = calculate_W(A_A1, B_A1, C_A1, A_S1, B_S1, C_S1)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, constrained_layout=True, figsize=(7,5))\n",
    "color = \"viridis\"\n",
    "\n",
    "A_A1_new = A_A1 @ w[:,:,0].T \n",
    "B_A1_new = B_A1 @ w[:,:,1].T\n",
    "\n",
    "plt.sca(axs[0])\n",
    "plt.xticks(range(4), range(1,5), fontsize=22)\n",
    "plt.yticks(range(8), ['Clinton', 'Kaine', 'O\\'Malley', 'Sanders', 'Cruz', 'Kasich', 'Rubio', 'Trump'], fontsize=22)\n",
    "plt.sca(axs[1])\n",
    "plt.xticks(range(4), range(1,5), fontsize=22)\n",
    "plt.yticks(range(10), ['Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov'], fontsize=22)\n",
    "\n",
    "axs[0].imshow(A_A1_new, cmap=plt.get_cmap(color))\n",
    "axs[1].imshow(B_A1_new, cmap=plt.get_cmap(color))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = calculate_W(np.dot(A_A1,A_A2), np.dot(B_A1,B_A2), np.dot(C_A1,C_A2), A_S2, B_S2, C_S2)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, constrained_layout=True, figsize=(4.8,5))\n",
    "color = \"viridis\"\n",
    "\n",
    "A_new = np.dot(A_A1,A_A2) @ w[:,:,0].T\n",
    "B_new = np.dot(B_A1,B_A2) @ w[:,:,1].T\n",
    "\n",
    "plt.sca(axs[0])\n",
    "plt.xticks(range(2), range(1,3), fontsize=22)\n",
    "plt.yticks(range(8), ['Clinton', 'Kaine', 'O\\'Malley', 'Sanders', 'Cruz', 'Kasich', 'Rubio', 'Trump'], fontsize=22)\n",
    "plt.sca(axs[1])\n",
    "plt.xticks(range(2), range(1,3), fontsize=22)\n",
    "plt.yticks(range(10), ['Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov'], fontsize=22)\n",
    "\n",
    "axs[0].imshow(A_new, cmap=plt.get_cmap(color))\n",
    "axs[1].imshow(B_new, cmap=plt.get_cmap(color))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(range(0,8), range(1,9), fontsize=18)\n",
    "plt.yticks(range(0,4), range(1,5), fontsize=18)\n",
    "\n",
    "plt.imshow(C_S1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.xticks(range(0,8), range(1,9), fontsize=19)\n",
    "plt.yticks(range(0,2), range(1,3), fontsize=19)\n",
    "\n",
    "plt.imshow(C_S2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
